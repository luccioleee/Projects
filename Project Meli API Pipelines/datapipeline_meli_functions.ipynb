{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, select, MetaData, Table\n",
    "import requests\n",
    "import sqlalchemy as sa\n",
    "import urllib\n",
    "from datetime import date, datetime, timedelta\n",
    "from threading import Thread\n",
    "import math\n",
    "\n",
    "from sql_queries import sql_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRowNumber():\n",
    "    '''\n",
    "    to test the output of the function, first update example.json file in folder -> to do this, copy the output of the postman response in the dictionary\n",
    "    then run this function and compare the number of rows between AzureDB and the dataframe\n",
    "    '''\n",
    "    result = open(\"example.json\", 'r', encoding='utf-8')\n",
    "    result = json.loads(result.read())\n",
    "\n",
    "    df = pd.json_normalize(result['x'])\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets connections for AzureDB\n",
    "def getConnforMYSQL(f_data, accessType):\n",
    "    list_dialects = pyodbc.drivers()\n",
    "    \n",
    "    for dialect in list_dialects:\n",
    "        try:\n",
    "            server = f_data[accessType][\"server\"]\n",
    "            db = f_data[accessType][\"database\"]\n",
    "            uid = f_data[accessType][\"uid\"]\n",
    "            pwd = f_data[accessType][\"pwd\"]\n",
    "            driver = f_data[accessType][\"dialect_driver\"]\n",
    "            port = f_data[accessType][\"port\"]\n",
    "\n",
    "            if accessType == \"azureAccess\":\n",
    "                if dialect in f_data[accessType][\"list_workingDialects\"]:\n",
    "                    print (f\"trying the dialect: {dialect}\")\n",
    "\n",
    "                    connection_string = (\n",
    "                        \" Driver={%s}\" %dialect +\n",
    "                        \"; SERVER=%s\" %server + \n",
    "                        \"; Database=%s \" %db + \n",
    "                        \"; UID=%s\" %uid +\n",
    "                        \"; PWD=%s\" %pwd\n",
    "                    )\n",
    "                    \n",
    "                    quoted = urllib.parse.quote_plus(connection_string)\n",
    "                    quoted = f_data[accessType][\"dialect_driver\"] + quoted\n",
    "                    #engine = create_engine(quoted, fast_executemany=True).execution_options(isolation_level=\"AUTOCOMMIT\")\n",
    "                    engine = create_engine(quoted, fast_executemany=True)\n",
    "                    print (f\"engine created with dialect = {dialect}\")\n",
    "                    try:\n",
    "                        with engine.begin() as conn:\n",
    "                            df = pd.DataFrame([1], columns = ['test'])\n",
    "                            df.to_sql(\"connectionTestTable\", conn, if_exists=\"replace\", index = False)\n",
    "                            print(f\"engine test sucessful\")\n",
    "                            break\n",
    "                    except:\n",
    "                        print(f\"the dialect = {dialect} didn't work\")\n",
    "            else:\n",
    "                quoted = driver + uid + \":\" + pwd + \"@\" + server + \":\" + str(port) + \"/\" + db\n",
    "                engine = create_engine(quoted).execution_options(isolation_level=\"AUTOCOMMIT\")\n",
    "            str_error = None\n",
    "\n",
    "        except:\n",
    "            print('exception found, trying other dialect')\n",
    "            pass\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get response from API- \n",
    "def setupAPIrequest(utilities, extraParams, overrideHeaders, ending):\n",
    "    '''\n",
    "    utilities: the utilies file\n",
    "    extraParams: extraParams as Dictionary for adding params in the request\n",
    "    overrideHeaders: overrideHeaders as Dictionary for changing headers\n",
    "    ending: as string\n",
    "    '''\n",
    "    schemeHTTP = utilities[\"HTTP\"][\"schemeHTTP\"]\n",
    "    baseHTTP = utilities[\"HTTP\"][\"baseHTTP\"]\n",
    "    extraHTTP = utilities[\"HTTP\"][\"extraHTTP\"]\n",
    "    headers = utilities[\"HTTP\"][\"headers\"]\n",
    "    \n",
    "    #overrideHeaders\n",
    "    if overrideHeaders != \"\":\n",
    "        for key, value in overrideHeaders.items():\n",
    "            for header_key, header_value in headers.items():\n",
    "                if header_key == key:\n",
    "                    headers[key] = value\n",
    "\n",
    "    #check if there is params variables:\n",
    "    paramsHTTP = \"\"\n",
    "    for key, value in utilities[\"HTTP\"].items():\n",
    "        if key == \"params\":\n",
    "            for key, value in utilities[\"HTTP\"][\"params\"].items():\n",
    "                paramsHTTP = paramsHTTP + key + \"=\" + str(value) + \"&\"\n",
    "            paramsHTTP = \"?\" + paramsHTTP\n",
    "    if extraParams != \"\":\n",
    "        paramsHTTP = paramsHTTP + \"?\"\n",
    "        for key, value in extraParams.items():\n",
    "            paramsHTTP = paramsHTTP + key + \"=\" + str(value) + \"&\"\n",
    "        paramsHTTP = paramsHTTP[:-1]\n",
    "    completeHTTP = schemeHTTP + baseHTTP + extraHTTP + paramsHTTP + ending\n",
    "\n",
    "    print (completeHTTP)\n",
    "    \n",
    "    if utilities[\"HTTP\"][\"method\"] == \"get\":\n",
    "        response = requests.get(completeHTTP, headers=headers)\n",
    "    if utilities[\"HTTP\"][\"method\"] == \"post\":\n",
    "        response = requests.post(completeHTTP, headers=headers)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeSQL(conn_azure, sql_text):\n",
    "    '''\n",
    "    gets an AzureDB connection and a SQL code to run on the engine\n",
    "    Returns the result query\n",
    "    '''\n",
    "    query_answer = conn_azure.execute(sql_text)\n",
    "     \n",
    "    return query_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorHandle(errSeverity, errReason, additionalInfo, file, engine_azure):\n",
    "    '''\n",
    "    Handles error for logging in AzureDB:\n",
    "    errLocation should be: where is running, application that is running + file name, other info\n",
    "    errDescription should be: what went wrong probably\n",
    "    errProcedure should be: how to restart/check the schedule or other info + if it's ok to retry anytime\n",
    "    errSeverity: 1 to 5, where 1 is wait for next try and 5 is check immediately\n",
    "    the connection is the connection for the AzureDB\n",
    "    '''\n",
    "    print(\"started errorHandle\")\n",
    "\n",
    "    errProcedure = globals()['util'][\"errorSuggestedProcedure\"][errReason]\n",
    "    if additionalInfo != None:\n",
    "        errDescription = globals()['util'][\"errorDescription\"][errReason]\n",
    "    else:\n",
    "        errDescription = additionalInfo\n",
    "\n",
    "    errLocation = globals()[\"util\"][file][\"nfo\"][\"runLocation\"]\n",
    "    errRunFileName = globals()[\"util\"][file][\"nfo\"][\"runFileName\"]\n",
    "    errRetry = globals()[\"util\"][file][\"nfo\"][\"retryOption\"]\n",
    "\n",
    "    globals()['endTime'] = datetime.now()\n",
    "    timeDifference = (globals()['endTime'] - globals()['startTime'])\n",
    "    sql_text = f\"\"\"\n",
    "        INSERT INTO nfo_errorLogTable (errorDescription, errorProcedure, errorStartTime, errorLocation, errorRetry, errorDuration, errorSeverity)\n",
    "        VALUES ('{errDescription}', '{errProcedure}', '{globals()['startTime'].strftime(\"%m/%d/%Y %H:%M\")}', '{errLocation}: {errRunFileName}', '{errRetry}', {timeDifference.total_seconds()}, {errSeverity}) \n",
    "    \"\"\"\n",
    "    #tabela = Table('nfo_errorLogTable', MetaData(), autoload_with=engine_azure)\n",
    "    #query = sa.insert(tabela).values(errorDescription = errDescription, errorProcedure = errProcedure, errorTime = datetime.now().strftime(\"%d/%m/%Y, %H:%M\"), errorLocation = errLocation, errorSeverity = errSeverity)\n",
    "    \n",
    "    with engine_azure.begin() as conn:\n",
    "        conn.execute(sql_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successHandle(file, additionalInfo, runRowNumber, engine_azure):\n",
    "    '''\n",
    "    Input information on function run success in AzureDB:\n",
    "    :runFile: varchar(100) - describes the filename -> wms_function_vEstoqueConsulta.py\n",
    "    :runStartTime: datetime - describes the startTime \n",
    "    :runQueryName: varchar(100) - describes the queryName -> vEstoqueConsulta\n",
    "    :runInputLocation: varchar(100) - describes the location of the input -> WMS_API\n",
    "    :runOutputTable: varchar(100) - describes the Success outputTable in AzureDB -> wms_vEstoqueConsultaSuccess\n",
    "    :runLocation: varchar(100) - describes where the pipeline is running -> AWS_batch\n",
    "    :runDuration: datetime(100) - describes the run duration in seconds\n",
    "    :additionalInfo: varchar(100) - additional information, optional\n",
    "    :runRowNumber: (bigint) - describes how many rows were inserted in the table\n",
    "    :engine_azure: is the azureDB defined engine\n",
    "    '''\n",
    "    print(\"started successHandle\")\n",
    "    runFile = globals()[\"util\"][file][\"nfo\"][\"runFileName\"]\n",
    "    runQueryName = globals()[\"util\"][file][\"nfo\"][\"runQueryName\"]\n",
    "    runInputLocation = globals()[\"util\"][file][\"nfo\"][\"runInputLocation\"]\n",
    "    runOutputTable = globals()[\"util\"][file][\"nfo\"][\"runOutputSuccessTable\"]\n",
    "    runLocation = globals()[\"util\"][file][\"nfo\"][\"runLocation\"]\n",
    "\n",
    "    globals()['endTime'] = datetime.now()\n",
    "    timeDifference = (globals()['endTime'] - globals()['startTime'])\n",
    "\n",
    "    #comes with insertion\n",
    "    mainInsertionTimeDifference = (globals()['mainEndTime'] - globals()['mainInsertTime'])\n",
    "    \n",
    "    #should be changed to attention Len instead of time\n",
    "    globals()['attentionInsertTime'] = datetime.now()\n",
    "    globals()['attentionEndTime'] = datetime.now()\n",
    "    attentionInsertionTimeDifference = (globals()['attentionEndTime'] - globals()['attentionInsertTime'])\n",
    "    \n",
    "    sql_text = f\"\"\"\n",
    "        INSERT INTO nfo_successRunTable (runFile, runStartTime, runQueryName, runInputLocation, runOutputTable, runLocation, runDuration, runRowNumber, mainInsertionTimeDifference, attentionInsertionTimeDifference, additionalInfo)\n",
    "        VALUES ('{runFile}', '{globals()['startTime'].strftime(\"%m/%d/%Y %H:%M\")}', '{runQueryName}', '{runInputLocation}', '{runOutputTable}', '{runLocation}', '{timeDifference.total_seconds()}', {runRowNumber}, {mainInsertionTimeDifference.total_seconds()}, {attentionInsertionTimeDifference.total_seconds()} ,'{additionalInfo}') \n",
    "    \"\"\"\n",
    "    if globals()['util'][file][\"nfo\"][\"hasIdentifier\"] == \"y\":\n",
    "        sql_text = f\"\"\"\n",
    "        INSERT INTO nfo_successRunTable (runFile, runStartTime, runQueryName, runInputLocation, runOutputTable, runLocation, runDuration, runRowNumber, mainInsertionTimeDifference, attentionInsertionTimeDifference, additionalInfo, identifier, identifierValue)\n",
    "        VALUES ('{runFile}', '{globals()['startTime'].strftime(\"%m/%d/%Y %H:%M\")}', '{runQueryName}', '{runInputLocation}', '{runOutputTable}', '{runLocation}', '{timeDifference.total_seconds()}', {runRowNumber}, {mainInsertionTimeDifference.total_seconds()}, {attentionInsertionTimeDifference.total_seconds()} ,'{additionalInfo}', \n",
    "        '{globals()['util'][file][\"nfo\"][\"identifier\"]}' ,{globals()[\"max_identifiervalue\"]}) \n",
    "        \"\"\"\n",
    "\n",
    "    with engine_azure.begin() as conn:\n",
    "        conn.execute(sql_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attentionHandle(file, additionalInfo, runRowNumber, engine_azure):\n",
    "    '''\n",
    "    Input information on function run success in AzureDB:\n",
    "    :runFile: varchar(100) - describes the filename -> wms_function_vEstoqueConsulta.py\n",
    "    :runStartTime: datetime - describes the startTime \n",
    "    :runQueryName: varchar(100) - describes the queryName -> vEstoqueConsulta\n",
    "    :runInputLocation: varchar(100) - describes the location of the input -> WMS_API\n",
    "    :runOutputTable: varchar(100) - describes the attention outputTable in AzureDB -> wms_vEstoqueConsultaAttention\n",
    "    :runLocation: varchar(100) - describes where the pipeline is running -> AWS_batch\n",
    "    :runDuration: datetime(100) - describes the run duration in seconds\n",
    "    :additionalInfo: varchar(100) - additional information, optional\n",
    "    :runRowNumber: (bigint) - describes how many rows were inserted in the table\n",
    "    :engine_azure: is the azureDB defined engine\n",
    "    '''\n",
    "    print(\"started attentionhandle\")\n",
    "    runFile = globals()[\"util\"][file][\"nfo\"][\"runFileName\"]\n",
    "    runQueryName = globals()[\"util\"][file][\"nfo\"][\"runQueryName\"]\n",
    "    runInputLocation = globals()[\"util\"][file][\"nfo\"][\"runInputLocation\"]\n",
    "    runOutputTable = globals()[\"util\"][file][\"resultSuccessTable\"][file]\n",
    "    runLocation = globals()[\"util\"][file][\"nfo\"][\"runLocation\"]\n",
    "    timeDifference = (globals()['endTime'] - globals()['startTime'])\n",
    "    mainInsertionTimeDifference = (globals()['mainEndTime'] - globals()['mainInsertTime'])\n",
    "    attentionInsertionTimeDifference = (globals()['attentionEndTime'] - globals()['attentionInsertTime'])\n",
    "    sql_text = f\"\"\"\n",
    "        INSERT INTO nfo_attentionTable (runFile, runStartTime, runQueryName, runInputLocation, runOutputTable, runLocation, runDuration, runRowNumber, mainInsertionTimeDifference, attentionInsertionTimeDifference, additionalInfo)\n",
    "        VALUES ('{runFile}', '{globals()['startTime'].strftime(\"%m/%d/%Y %H:%M\")}', '{runInputLocation}', '{runQueryName}', '{runOutputTable}', '{runLocation}', '{timeDifference.total_seconds()}', {runRowNumber} , {mainInsertionTimeDifference.total_seconds()}, {attentionInsertionTimeDifference.total_seconds()},'{additionalInfo}') \n",
    "    \"\"\"\n",
    "    with engine_azure.begin() as conn:\n",
    "        conn.execute(sql_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCorrectTypes(dataFrame, columnsTypes_dict, list_dfAttention):\n",
    "    '''\n",
    "    gets a normalized data frame and a list of columns in a dictionary to change column type on the dataFrame\n",
    "    returns a list_dfAttention a list with datetime errors, dataframe with the altered columns \n",
    "    '''\n",
    "    for column in dataFrame:\n",
    "        for key, value in columnsTypes_dict.items():\n",
    "            if column == key:\n",
    "                data_type = value[\"type\"]\n",
    "                data_format = value[\"format\"]\n",
    "                #copy the df to errDataTime\n",
    "                errDataFrame = dataFrame\n",
    "\n",
    "                #remove empty column cells\n",
    "                errDataFrame = errDataFrame[errDataFrame[column].astype(bool)]\n",
    "                #reindex the errDateTime to match with mask\n",
    "                errDataFrame.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                #create a mask where the convertion to datetime fails\n",
    "                if data_type == \"to_datetime\":\n",
    "                    mask = pd.to_datetime(errDataFrame[column], format=data_format, errors='coerce').isna()\n",
    "                if data_type == \"to_numeric\":\n",
    "                    mask = pd.to_numeric(errDataFrame[column], errors='coerce').isna()\n",
    "\n",
    "                #apply to df the mask from the substitution\n",
    "                errDataFrame = errDataFrame[mask]\n",
    "\n",
    "                #reindex the errDatetime\n",
    "                errDataFrame.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                #append dataframe to be concatenated after only if there is > 1 row in the df\n",
    "                if len(errDataFrame) > 0:\n",
    "                    list_dfAttention.append(errDataFrame)\n",
    "\n",
    "                #the main Dataframe is kept with all the data (and the errors are coerced)\n",
    "                if data_type ==  \"to_datetime\":\n",
    "                    dataFrame[column].fillna(\"\", inplace=True)\n",
    "                    dataFrame[column] = pd.to_datetime(dataFrame[column], format=data_format, errors=\"coerce\")\n",
    "                    dataFrame[column] = dataFrame[column].dt.tz_localize(None)\n",
    "                if data_type == \"to_numeric\":\n",
    "                    dataFrame[column].fillna(0, inplace=True)\n",
    "                    #remove commas in case the numbers are stored as string\n",
    "                    dataFrame[column] = dataFrame[column].replace(regex = {'[^0-9]', ''})\n",
    "                    dataFrame[column] = dataFrame[column].replace(regex = {',', '.'})\n",
    "                    #change dType\n",
    "                    dataFrame[column] = pd.to_numeric(dataFrame[column], errors='coerce')\n",
    "                break\n",
    "        if dataFrame[column].dtype == int or dataFrame[column].dtype == float :\n",
    "            dataFrame[column].fillna(0, inplace=True)\n",
    "        else:\n",
    "            dataFrame[column].fillna(\"\", inplace=True)\n",
    "    return dataFrame, list_dfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subthreadMain:\n",
    "    def __init__(self, client , file, engine_azure, extraparams, overrideHeaders, ending, extra_nfo, mode):\n",
    "        self.client = client\n",
    "\n",
    "        self.file = file\n",
    "        self.response = None\n",
    "        self.response_dict = None\n",
    "\n",
    "        self.extraparams = extraparams\n",
    "        self.overrideHeaders = overrideHeaders\n",
    "        self.ending = ending\n",
    "\n",
    "        #set engine and connection\n",
    "        self.engine_azure = engine_azure\n",
    "        self.conn_azure = self.engine_azure.connect()\n",
    "\n",
    "        if mode == \"order_task\" :\n",
    "            self.t = Thread(target=self.subthreadOrderTask, args=())\n",
    "            self.t.start()\n",
    "        elif mode == \"shipment_task\":\n",
    "            self.this_shipment = extra_nfo\n",
    "            if self.ending != 'None':\n",
    "                self.t = Thread(target=self.subthreadShipmentTask, args=())\n",
    "                self.t.start()\n",
    "            else:\n",
    "                self.t = Thread(target=self.subthreadskip, args=())\n",
    "                self.t.start()\n",
    "        elif mode == \"reputation_task\":\n",
    "            self.t = Thread(target=self.subthreadReputationTask, args=())\n",
    "            self.t.start()\n",
    "\n",
    "    def getsubThread(self):\n",
    "        return (self.t)\n",
    "    \n",
    "    def subthreadOrderTask(self):\n",
    "        #print (f\"starting page: {self.extraparams['offset']}\")\n",
    "        self.response = setupAPIrequest(globals()['util']['meli_get_seller_orders'], self.extraparams, self.overrideHeaders, self.ending)\n",
    "        self.response_dict = json.loads(self.response.text)\n",
    "        print('next block:')\n",
    "        #print (self.response_dict['results'])\n",
    "        #for item in self.response_dict['results']:\n",
    "        #    print(item['id'])\n",
    "        #create the orders list of client\n",
    "        for each_order in self.response_dict['results']:\n",
    "            #get order id\n",
    "            new_order = order()\n",
    "            new_order.rawtext = each_order\n",
    "            new_order.order_id = each_order['id']\n",
    "            new_order.status = each_order['status']\n",
    "            #get payment nfo\n",
    "            for each_payment in each_order['payments']:\n",
    "                new_payment = payment()\n",
    "                new_payment.payment_approvation_date = each_payment['date_approved']\n",
    "                new_payment.payment_status = each_payment['status']\n",
    "                new_payment.payment_id = each_payment['id']\n",
    "                new_payment.rawtext = each_payment\n",
    "                new_order.list_payments += [new_payment]\n",
    "            #get items nfo\n",
    "            for each_item in each_order['order_items']:\n",
    "                new_item = item()\n",
    "                new_item.rawtext = each_item\n",
    "                new_order.list_items += [new_item]\n",
    "            #get shipment nfo\n",
    "            new_shipment = shipment()\n",
    "            new_shipment.shipment_id = each_order['shipping']['id']\n",
    "            new_order.list_shipments += [new_shipment]\n",
    "\n",
    "            #add to orders list\n",
    "            self.client.orders_list += [new_order]\n",
    "\n",
    "            print(new_order.order_id)\n",
    "    \n",
    "    def subthreadskip(self):\n",
    "        pass\n",
    "\n",
    "    def subthreadShipmentTask(self):\n",
    "        response = setupAPIrequest(globals()['util']['meli_get_shipping_nfo'], self.extraparams, self.overrideHeaders, self.ending)\n",
    "        response_dict = json.loads(response.text)\n",
    "        self.this_shipment.rawtext = response_dict\n",
    "        self.this_shipment.estimated_delivery_limit = response_dict['shipping_option']['estimated_delivery_limit']\n",
    "        self.this_shipment.estimated_handling_limit = response_dict['shipping_option']['estimated_handling_limit']\n",
    "        self.this_shipment.shipment_id = response_dict['id']\n",
    "        self.this_shipment.shipment_substatus = response_dict['substatus']\n",
    "        self.this_shipment.shipment_status = response_dict['status']\n",
    "        self.this_shipment.tracking_number = response_dict['tracking_number']\n",
    "        self.this_shipment.tracking_method = response_dict['tracking_method']\n",
    "\n",
    "    def subthreadReputationTask(self):\n",
    "        response = setupAPIrequest(globals()['util']['meli_get_seller_reputation'], self.extraparams, self.overrideHeaders, self.ending)\n",
    "        response_dict = json.loads(response.text)\n",
    "        #only one reputation for each seller\n",
    "        this_seller_reputation = reputation()\n",
    "        this_seller_reputation.rawtext = response_dict\n",
    "        this_seller_reputation.rawtext['result_date'] = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        this_seller_reputation.level_id = response_dict['seller_reputation']['level_id']\n",
    "        this_seller_reputation.result_date = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        #the reputation_raw needs a column of date to track evolution of the reputation\n",
    "\n",
    "        self.client.seller_reputation = this_seller_reputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class threadMain:\n",
    "    def __init__(self, client , file, engine_azure):\n",
    "        #set variables\n",
    "        self.client = client\n",
    "        print (f'starting process for {self.client._client_name}')\n",
    "\n",
    "        #sets variables for the rules\n",
    "        self.list_regrasGMV = []\n",
    "        self.list_regrasOther = []\n",
    "\n",
    "        #set dates\n",
    "        \n",
    "        #set engine and connection\n",
    "        self.engine_azure = engine_azure\n",
    "        self.conn_azure = self.engine_azure.connect()\n",
    "\n",
    "        #initialize client subthreads\n",
    "        self.subthreads = []\n",
    "\n",
    "        self.file = file\n",
    "        #start the thread\n",
    "        self.t = Thread(target=self.threadMainTask, args=())\n",
    "        self.t.start()\n",
    "\n",
    "    def getThread(self):\n",
    "        return (self.t)\n",
    "\n",
    "    def _test_access_token(self):\n",
    "        overrideHeaders = \"\"\n",
    "        ending = \"\"\n",
    "        extraparams = {\n",
    "            'grant_type' : 'refresh_token',\n",
    "            'client_id' : self.client._client_id,\n",
    "            'client_secret' : self.client._client_secret,\n",
    "            'refresh_token' : self.client.new_refresh_token\n",
    "            }\n",
    "        response = setupAPIrequest(globals()['util']['meli_get_access_token'], extraparams, overrideHeaders, ending)\n",
    "        if response.status_code == 400:\n",
    "            response_dict = json.loads(response.text)\n",
    "            if response_dict['error'] == 'invalid_grant':\n",
    "                #try with the refresh_token_payload\n",
    "                self.client.new_refresh_token = self.client._refresh_token_payload\n",
    "                overrideHeaders = \"\"\n",
    "                ending = \"\"\n",
    "                extraparams = {\n",
    "                    'grant_type' : 'refresh_token',\n",
    "                    'client_id' : self.client._client_id,\n",
    "                    'client_secret' : self.client._client_secret,\n",
    "                    'refresh_token' : self.client.new_refresh_token\n",
    "                    }\n",
    "                response = setupAPIrequest(globals()['util']['meli_get_access_token'], extraparams, overrideHeaders, ending)\n",
    "                if response.status_code != 200:\n",
    "                    print ('token inválido')\n",
    "\n",
    "\n",
    "    def _getaccesstoken(self):\n",
    "        self._test_access_token()\n",
    "        #get access token from meli\n",
    "        overrideHeaders = \"\"\n",
    "        ending = \"\"\n",
    "        extraparams = {\n",
    "            'grant_type' : 'refresh_token',\n",
    "            'client_id' : self.client._client_id,\n",
    "            'client_secret' : self.client._client_secret,\n",
    "            'refresh_token' : self.client.new_refresh_token\n",
    "            }\n",
    "        response = setupAPIrequest(globals()['util']['meli_get_access_token'], extraparams, overrideHeaders, ending)\n",
    "        #response is in json format\n",
    "        response_dict = json.loads(response.text)\n",
    "        #update client class with access token and new info\n",
    "        self.client.access_token = response_dict['access_token']\n",
    "        self.client.used_refresh_token = self.client.new_refresh_token\n",
    "        self.client.new_refresh_token = response_dict['refresh_token']\n",
    "        self.client.user_id = response_dict['user_id']\n",
    "\n",
    "    def _getordersfromseller(self): #todo -> dividir por thread por página para acelerar os downloads, descobrir porque ele fica vindo pedido repetido embora muda de página\n",
    "        #seller as same as client\n",
    "        #get orders from meli\n",
    "        time_from = (datetime.now() - timedelta(days = 7)).strftime(\"%Y-%m-%d\") + \"T00:00:00-00:00\"\n",
    "        time_to = datetime.now().strftime(\"%Y-%m-%d\") + \"T\" + datetime.now().strftime(\"%H:%M:%S\") + \"-00:00\"\n",
    "        print (\"time_from :\", time_from)\n",
    "        print (\"time_to :\", time_to)    \n",
    "        ending = \"\"\n",
    "        extraparams = {\n",
    "            'seller' : self.client.user_id,\n",
    "            'order.date_created.from' : time_from,\n",
    "            'order.date_created.to'   : time_to,\n",
    "            }\n",
    "        #add a header\n",
    "        overrideHeaders = {\n",
    "            \"Authorization\": \"Bearer %s\" %self.client.access_token\n",
    "            }\n",
    "        response = setupAPIrequest(globals()['util']['meli_get_seller_orders'], extraparams, overrideHeaders, ending)\n",
    "        response_dict = json.loads(response.text)\n",
    "        \n",
    "        #page_number\n",
    "        print (f\"expected total orders: {response_dict['paging']['total']}\")\n",
    "        retrieve_limit = 50\n",
    "        page_number = response_dict[\"paging\"][\"total\"]/retrieve_limit\n",
    "        for page in range(math.ceil(page_number)):\n",
    "            extraparams['offset'] = page*retrieve_limit\n",
    "            extraparams['limit'] = retrieve_limit\n",
    "            extraparams['sort'] = 'date_desc'\n",
    "\n",
    "            t = subthreadMain(self.client, self.file, self.engine_azure, extraparams, overrideHeaders, ending, None, \"order_task\")\n",
    "            self.subthreads.append(t.getsubThread())\n",
    "            \n",
    "            for t in self.subthreads:\n",
    "                t.join()\n",
    "\n",
    "    def _getshippingnfo(self):         \n",
    "        #get shipping information of the order\n",
    "        for each_order in self.client.orders_list:\n",
    "            for each_shipment in each_order.list_shipments:\n",
    "\n",
    "                shipment_id = each_shipment.shipment_id\n",
    "                this_shipment = each_shipment\n",
    "\n",
    "                extraparams = {\n",
    "                    }\n",
    "                #add a header\n",
    "                overrideHeaders = {\n",
    "                    \"Authorization\": \"Bearer %s\" %self.client.access_token\n",
    "                    }\n",
    "                ending = str(shipment_id)\n",
    "\n",
    "                t = subthreadMain(self.client, self.file, self.engine_azure, extraparams, overrideHeaders, ending, this_shipment, \"shipment_task\")\n",
    "                self.subthreads.append(t.getsubThread())\n",
    "\n",
    "                for t in self.subthreads:\n",
    "                    t.join()\n",
    "                \n",
    "    def _getsellerreputation(self):\n",
    "        extraparams = {\n",
    "            }\n",
    "        #add a header\n",
    "        overrideHeaders = {\n",
    "            \"Authorization\": \"Bearer %s\" %self.client.access_token\n",
    "            }\n",
    "        ending = str(self.client.user_id)\n",
    "\n",
    "        t = subthreadMain(self.client, self.file, self.engine_azure, extraparams, overrideHeaders, ending, None, \"reputation_task\")\n",
    "        self.subthreads.append(t.getsubThread())\n",
    "\n",
    "        for t in self.subthreads:\n",
    "            t.join()\n",
    "        \n",
    "    def _remove_keys(self, dictionary, keys_to_remove):\n",
    "        #to remove keys of a dictionary\n",
    "        return {k: v for k, v in dictionary.items() if k not in keys_to_remove}\n",
    "    \n",
    "    def threadMainTask(self):\n",
    "        #get the access token from meli\n",
    "        self._getaccesstoken()\n",
    "\n",
    "        #insert into newTokens list for insertion on nfo_meliTokenTable (to keep updated)\n",
    "        globals()['list_response_newTokens'] += [{\n",
    "            'client_id': self.client._client_id,\n",
    "            'used_refresh_token': self.client.used_refresh_token,\n",
    "            'refresh_time': datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\"),\n",
    "            'new_refresh_token': self.client.new_refresh_token\n",
    "            }]\n",
    "\n",
    "        #get orders from meli of the client\n",
    "        self._getordersfromseller()\n",
    "\n",
    "        #get reputation of the client\n",
    "        self._getsellerreputation()\n",
    "\n",
    "        #get shipping nfo of the client\n",
    "        self._getshippingnfo()\n",
    "\n",
    "        #start data processing (T)\n",
    "        #this is specific for asked table\n",
    "        result_client_name = self.client._client_name\n",
    "        result_client_id = self.client.client_id\n",
    "        for each_order in self.client.orders_list:\n",
    "            result_order_id = each_order.order_id\n",
    "            for each_shipment in each_order.list_shipments:\n",
    "                globals()['list_summaryTable_shipments'] += [{\n",
    "                    'result_client_name' : result_client_name,\n",
    "                    'result_client_id' : result_client_id,\n",
    "                    'result_order_id' : result_order_id,\n",
    "                    'result_shipment_id' : each_shipment.shipment_id,\n",
    "                    'result_estimated_delivery_limit' : each_shipment.estimated_delivery_limit,\n",
    "                    'result_estimated_handling_limit' : each_shipment.estimated_handling_limit,\n",
    "                    'result_shipment_status' : each_shipment.shipment_status,\n",
    "                    'result_shipment_shipment_substatus' : each_shipment.shipment_substatus,\n",
    "                    'result_shipment_tracking_number' : each_shipment.tracking_number,\n",
    "                    'result_shipment_tracking_method' : each_shipment.tracking_method\n",
    "                }]\n",
    "                #insert shipments info into raw table\n",
    "                globals()['list_rawTable_shipments'] += [each_shipment.rawtext]\n",
    "\n",
    "            \n",
    "            for each_payment in each_order.list_payments:\n",
    "                globals()['list_summaryTable_payments'] += [{\n",
    "                    'result_client_name' : result_client_name,\n",
    "                    'result_client_id' : result_client_id,\n",
    "                    'result_order_id' : result_order_id,\n",
    "                    'result_payment_id' : each_payment.payment_id,\n",
    "                    'result_payment_status' : each_payment.payment_status,\n",
    "                    'result_payment_approvation_date' : each_payment.payment_approvation_date\n",
    "                }]\n",
    "                \n",
    "            #this is to create the generic table (with all nfo)\n",
    "            #print (each_order)\n",
    "            globals()['list_rawTable_payments'] += each_order.rawtext['payments']\n",
    "            \n",
    "            #remove certain keys of each_order to make the rawTable_orders\n",
    "            invalid = {\"payments\", \"order_items\",\"tags\"}\n",
    "            result_order = self._remove_keys(each_order.rawtext, invalid)\n",
    "            globals()['list_rawTable_orders'] += [result_order]\n",
    "        \n",
    "        #place seller reputation on the global table\n",
    "        #for summarized table\n",
    "        globals()['list_summaryTable_reputation'] += [{\n",
    "            'result_client_id' : result_client_id,\n",
    "            'result_client_name' : result_client_name,\n",
    "            'result_date' : self.client.seller_reputation.result_date,\n",
    "            'result_level_id' : self.client.seller_reputation.level_id\n",
    "        }]\n",
    "        #for generic table\n",
    "        globals()['list_rawTable_reputation'] += [self.client.seller_reputation.rawtext]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class order:\n",
    "    def __init__(self):\n",
    "        self.order_id = None\n",
    "        self.rawtext = None\n",
    "        self.status = None\n",
    "        self.list_shipments = []\n",
    "        self.list_payments = []\n",
    "        self.list_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class item:\n",
    "    def __init__(self):\n",
    "        self.rawtext = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class payment:\n",
    "    def __init__(self):\n",
    "        self.payment_status = None\n",
    "        self.payment_approvation_date = None\n",
    "        self.payment_id = None\n",
    "        self.rawtext = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class shipment:\n",
    "    def __init__(self):\n",
    "        self.rawtext = None\n",
    "        self.shipment_id = None\n",
    "        self.tracking_number = None\n",
    "        self.estimated_delivery_limit = None\n",
    "        self.estimated_handling_limit = None\n",
    "        self.shipment_status = None\n",
    "        self.shipment_substatus = None\n",
    "        self.tracking_method = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class client:\n",
    "    def __init__(self, refresh_id, client_id, used_refresh_token, new_refresh_token) -> None:\n",
    "        #set variables:\n",
    "        self._client_id = client_id\n",
    "        self.refresh_id = refresh_id\n",
    "        self.used_refresh_token = used_refresh_token\n",
    "        self.new_refresh_token = new_refresh_token\n",
    "        self._client_name = None\n",
    "        self._client_secret = None\n",
    "        self._refresh_token_payload = None\n",
    "        self.access_token = None\n",
    "        self.user_id = None\n",
    "        self.orders_list = []\n",
    "        self.seller_reputation = None\n",
    "\n",
    "    @property\n",
    "    def client_id(self):\n",
    "        return self._client_id\n",
    "\n",
    "    def add_other_variables(self, client_name, client_secret, refresh_token_payload):\n",
    "        self._client_name = client_name\n",
    "        self._client_secret = client_secret\n",
    "        self._refresh_token_payload = refresh_token_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reputation:\n",
    "    def __init__(self):\n",
    "        self.rawtext = None\n",
    "        self.result_date = None\n",
    "        self.level_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_upsert(data_frame, table_name, engine, schema=None, match_columns=None):\n",
    "    \"\"\"\n",
    "    Perform an \"upsert\" on a SQL Server table from a DataFrame.\n",
    "    Constructs a T-SQL MERGE statement, uploads the DataFrame to a\n",
    "    temporary table, and then executes the MERGE.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_frame : pandas.DataFrame\n",
    "        The DataFrame to be upserted.\n",
    "    table_name : str\n",
    "        The name of the target table.\n",
    "    engine : sqlalchemy.engine.Engine\n",
    "        The SQLAlchemy Engine to use.\n",
    "    schema : str, optional\n",
    "        The name of the schema containing the target table.\n",
    "    match_columns : list of str, optional\n",
    "        A list of the column name(s) on which to match. If omitted, the\n",
    "        primary key columns of the target table will be used.\n",
    "    \"\"\"\n",
    "    table_spec = \"\"\n",
    "    if schema:\n",
    "        table_spec += \"[\" + schema.replace(\"]\", \"]]\") + \"].\"\n",
    "    table_spec += \"[\" + table_name.replace(\"]\", \"]]\") + \"]\"\n",
    "\n",
    "    df_columns = list(data_frame.columns)\n",
    "    if not match_columns:\n",
    "        insp = sa.inspect(engine)\n",
    "        match_columns = insp.get_pk_constraint(table_name, schema=schema)[\n",
    "            \"constrained_columns\"\n",
    "        ]\n",
    "    columns_to_update = [col for col in df_columns if col not in match_columns]\n",
    "    stmt = f\"MERGE {table_spec} WITH (HOLDLOCK) AS main\\n\"\n",
    "    stmt += f\"USING (SELECT {', '.join([f'[{col}]' for col in df_columns])} FROM #temp_table) AS temp\\n\"\n",
    "    join_condition = \" AND \".join(\n",
    "        [f\"main.[{col}] = temp.[{col}]\" for col in match_columns]\n",
    "    )\n",
    "    stmt += f\"ON ({join_condition})\\n\"\n",
    "    stmt += \"WHEN MATCHED THEN\\n\"\n",
    "    update_list = \", \".join(\n",
    "        [f\"[{col}] = temp.[{col}]\" for col in columns_to_update]\n",
    "    )\n",
    "    stmt += f\"  UPDATE SET {update_list}\\n\"\n",
    "    stmt += \"WHEN NOT MATCHED THEN\\n\"\n",
    "    insert_cols_str = \", \".join([f\"[{col}]\" for col in df_columns])\n",
    "    insert_vals_str = \", \".join([f\"temp.[{col}]\" for col in df_columns])\n",
    "    stmt += f\"  INSERT ({insert_cols_str}) VALUES ({insert_vals_str});\"\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        data_frame.to_sql(\"#temp_table\", conn, index=False)\n",
    "        conn.exec_driver_sql(stmt)\n",
    "        conn.exec_driver_sql(\"DROP TABLE IF EXISTS #temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_removeLists(data_frame):\n",
    "    \"\"\"\n",
    "    Removes the columns that contains lists in the data_frame\n",
    "    returns the data_frame\n",
    "    warning: the column data is lost\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_frame : pandas.DataFrame\n",
    "        The DataFrame to be upserted.\n",
    "    \"\"\"\n",
    "    #dfmask = ((data_frame.map(type) == list).all())\n",
    "    #print (dfmask)\n",
    "    #list_mask = (dfmask.mask(dfmask == False).dropna().index.to_list())\n",
    "    #print (list_mask)\n",
    "    list_mask = data_frame.columns[data_frame.applymap(lambda x: isinstance(x, list)).any()].tolist()\n",
    "    return data_frame.drop(columns=list_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file):\n",
    "    #open auth file for azureDB\n",
    "    auth = open('auth.json')\n",
    "    auth_load = json.load(auth)\n",
    "    \n",
    "    #create AzureDB connection\n",
    "    engine_azure = getConnforMYSQL(auth_load, \"azureAccess\")\n",
    "    conn_azure = engine_azure.connect()\n",
    "\n",
    "    #get utilities content\n",
    "    util = open('utilities.json')\n",
    "    utilities_load = json.load(util)\n",
    "    globals()['util'] = utilities_load\n",
    "    \n",
    "    #creat a list to insert new tokens in nfo_meliTokenTable\n",
    "    globals()['list_response_newTokens'] = []\n",
    "\n",
    "    globals()['list_summaryTable_payments'] = []\n",
    "    globals()['list_summaryTable_shipments'] = []\n",
    "    globals()['list_summaryTable_reputation'] = []\n",
    "    globals()['list_rawTable_payments'] = []\n",
    "    globals()['list_rawTable_shipments'] = []\n",
    "    globals()['list_rawTable_reputation'] = []\n",
    "    \n",
    "    globals()['list_rawTable_orders'] = []\n",
    "\n",
    "    globals()['allok'] = False\n",
    "\n",
    "    #create a clients list\n",
    "    list_clients = []\n",
    "\n",
    "    #get list of ongoing tokens\n",
    "    list_tokens = executeSQL(conn_azure, sql_list[\"getongointokenslist\"])\n",
    "    for row in list_tokens.all():\n",
    "        n_coluna = 0\n",
    "        for coluna in list_tokens.keys():\n",
    "            if coluna == \"refresh_id\":\n",
    "                refresh_id = row[n_coluna]\n",
    "            if coluna == \"client_id\":\n",
    "                client_id = row[n_coluna]\n",
    "            if coluna == \"used_refresh_token\":\n",
    "                used_refresh_token = row[n_coluna]\n",
    "            if coluna == \"new_refresh_token\":\n",
    "                new_refresh_token = row[n_coluna]\n",
    "            n_coluna = n_coluna + 1\n",
    "        new_client = client(refresh_id, client_id, used_refresh_token, new_refresh_token)\n",
    "        list_clients += [new_client]\n",
    "\n",
    "    #get list of clients from AzureDB \n",
    "    globals()['response_list'] = []\n",
    "    threads = []\n",
    "    list_filiais = executeSQL(conn_azure, sql_list[\"getclientslist\"])\n",
    "    for row in list_filiais.all():\n",
    "        n_coluna = 0\n",
    "        #first find the client in client list\n",
    "        for coluna in list_filiais.keys():\n",
    "            if coluna == \"client_id\":\n",
    "                client_id = row[n_coluna]\n",
    "                client_not_found = True\n",
    "                for each_client in list_clients:\n",
    "                    if each_client._client_id == client_id :\n",
    "                        this_client = each_client\n",
    "                        client_not_found = False\n",
    "                        break\n",
    "            n_coluna += 1\n",
    "        n_coluna = 0 \n",
    "        #then find every information of the client\n",
    "        for coluna in list_filiais.keys():\n",
    "            if coluna == \"client_name\":\n",
    "                client_name = row[n_coluna]\n",
    "            if coluna == \"client_secret\":\n",
    "                client_secret = row[n_coluna]\n",
    "            if coluna == \"refresh_token_payload\":\n",
    "                refresh_token_payload = row[n_coluna]\n",
    "            if coluna == \"client_id\":\n",
    "                client_id = row[n_coluna]\n",
    "            n_coluna = n_coluna + 1\n",
    "\n",
    "        #update client information\n",
    "        if client_not_found:\n",
    "            #create a client - that was recently inserted\n",
    "            refresh_id = None\n",
    "            used_refresh_token = refresh_token_payload\n",
    "            new_refresh_token = refresh_token_payload\n",
    "            this_client = client(refresh_id, client_id, used_refresh_token, new_refresh_token)\n",
    "            this_client.add_other_variables(client_name, client_secret, refresh_token_payload)\n",
    "        else:\n",
    "            this_client.add_other_variables(client_name, client_secret, refresh_token_payload)\n",
    "        t = threadMain(this_client, file, engine_azure)\n",
    "        threads.append(t.getThread())\n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    #setup global variable for the outcome of the connection\n",
    "    globals()['output'] = \"Failed\"    \n",
    "    print (len(globals()['list_summaryTable_payments']))\n",
    "\n",
    "    #insert to azureDB\n",
    "    list_dfAttention = []      \n",
    "    try:\n",
    "        #start cleaning/changing dType of data\n",
    "        #summary dont need to drop because it is made in the code\n",
    "        df_meli_newTokens = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_response_newTokens'], sep= '_'))\n",
    "        \n",
    "        df_meli_payments_summary = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_summaryTable_payments'], sep= '_'))\n",
    "        df_meli_shipments_summary = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_summaryTable_shipments'], sep= '_'))\n",
    "        df_meli_reputation_summary = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_summaryTable_reputation'], sep= '_'))\n",
    "        \n",
    "\n",
    "        #drop some columns that contains lists #temporary - rawdata\n",
    "        df_meli_payments_raw = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_rawTable_payments'], sep= '_'))\n",
    "        df_meli_payments_raw = df_removeLists(df_meli_payments_raw)\n",
    "        df_meli_shipments_raw = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_rawTable_shipments'], sep = '_'))\n",
    "        df_meli_shipments_raw = df_removeLists(df_meli_shipments_raw)\n",
    "        df_meli_reputation_raw = pd.DataFrame.from_dict(pd.json_normalize(globals()['list_rawTable_reputation'], sep = '_'))\n",
    "        df_meli_reputation_raw = df_removeLists(df_meli_reputation_raw)\n",
    "        \n",
    "        df_meli_orders_raw = pd.DataFrame.from_dict(globals()['list_rawTable_orders'])\n",
    "        \n",
    "        df_meli_shipments_summary, list_dfAttention = fCorrectTypes(df_meli_shipments_summary, globals()['util'][file][\"columnsType_dict\"][\"meli_shipments_summary\"], list_dfAttention)\n",
    "        df_meli_shipments_summary = df_meli_shipments_summary.drop_duplicates()\n",
    "        df_meli_payments_summary, list_dfAttention = fCorrectTypes(df_meli_payments_summary, globals()['util'][file][\"columnsType_dict\"][\"meli_payments_summary\"], list_dfAttention)\n",
    "        df_meli_payments_summary = df_meli_payments_summary.drop_duplicates()\n",
    "        \n",
    "        df_meli_payments_raw, list_dfAttention = fCorrectTypes(df_meli_payments_raw, globals()['util'][file][\"columnsType_dict\"][\"meli_payments_raw\"], list_dfAttention)\n",
    "        df_meli_payments_raw = df_meli_payments_raw.drop_duplicates()\n",
    "        df_meli_shipments_raw, list_dfAttention = fCorrectTypes(df_meli_shipments_raw, globals()['util'][file][\"columnsType_dict\"][\"meli_shipments_raw\"], list_dfAttention)\n",
    "        df_meli_shipments_raw = df_meli_shipments_raw.drop_duplicates()\n",
    "        df_meli_reputation_raw, list_dfAttention = fCorrectTypes(df_meli_reputation_raw, globals()['util'][file][\"columnsType_dict\"][\"meli_reputation_raw\"], list_dfAttention)\n",
    "        df_meli_reputation_raw = df_meli_reputation_raw.drop_duplicates()\n",
    "\n",
    "        if len(globals()['list_summaryTable_shipments']) > 0:\n",
    "            try:\n",
    "                #insert into AzureDB the main df\n",
    "                print (f'{file} starting mainInsertion time: {datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}')\n",
    "                globals()['mainInsertTime'] = datetime.now()\n",
    "\n",
    "                df_meli_newTokens.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_newTokens\"], engine_azure, if_exists='append', index=False)\n",
    "                \n",
    "                #df_meli_shipments_summary.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_shipments_summary\"], engine_azure, if_exists='replace', index=False)\n",
    "                #df_meli_payments_summary.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_payments_summary\"], engine_azure, if_exists='replace', index=False)\n",
    "                df_meli_reputation_summary.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_reputation_summary\"], engine_azure, if_exists='append', index=False)\n",
    "                #df_meli_payments_raw.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_payments_raw\"], engine_azure, if_exists='replace', index=False)\n",
    "                #df_meli_shipments_raw.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_shipments_raw\"], engine_azure, if_exists='replace', index=False)\n",
    "                df_meli_reputation_raw.to_sql(utilities_load[file][\"resultSuccessTable\"][\"meli_reputation_raw\"], engine_azure, if_exists='append', index=False)\n",
    "                \n",
    "                #upsert information\n",
    "                df_upsert(df_meli_shipments_summary, utilities_load[file][\"resultSuccessTable\"][\"meli_shipments_summary\"], engine_azure, match_columns= ['result_shipment_id', 'result_client_id', 'result_order_id'])\n",
    "                df_upsert(df_meli_payments_summary, utilities_load[file][\"resultSuccessTable\"][\"meli_payments_summary\"], engine_azure, match_columns= ['result_payment_id', 'result_client_id', 'result_order_id'])\n",
    "                df_upsert(df_meli_payments_raw, utilities_load[file][\"resultSuccessTable\"][\"meli_payments_raw\"], engine_azure, match_columns= ['id', 'order_id'])\n",
    "                df_upsert(df_meli_shipments_raw, utilities_load[file][\"resultSuccessTable\"][\"meli_shipments_raw\"], engine_azure, match_columns= ['id', 'order_id'])\n",
    "                \n",
    "                globals()['mainEndTime'] = datetime.now()\n",
    "                \n",
    "                #mark clocks\n",
    "                globals()['endTime'] = datetime.now()\n",
    "                globals()['attentionInsertTime'] = datetime.now()\n",
    "                globals()['attentionEndTime'] = datetime.now()\n",
    "\n",
    "                #for the main DataFrame\n",
    "                successHandle(file= file, additionalInfo= \"\", runRowNumber= (len(df_meli_reputation_raw) + len(df_meli_payments_raw) + len(df_meli_shipments_raw)), engine_azure= engine_azure)\n",
    "                globals()['output'] = \"Success\"\n",
    "            except:\n",
    "                errorHandle(2, \"insertAzureDB\", None, file, engine_azure)\n",
    "        else:\n",
    "            #if there is no data after TransID then call successHandle\n",
    "            globals()[\"max_identifiervalue\"] = None\n",
    "            globals()['mainInsertTime'] = datetime.now()\n",
    "            globals()['mainEndTime'] = datetime.now()\n",
    "            globals()['output'] = 'Success'\n",
    "            successHandle(file= file, additionalInfo= \"no new trans_id\", runRowNumber= 0, engine_azure = engine_azure)\n",
    "    except:\n",
    "        errorHandle(2, \"failedDataFrame\", None, file, engine_azure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapipeline_meli_functions start time: 15/12/2023 13:23:00\n",
      "trying the dialect: ODBC Driver 18 for SQL Server\n",
      "engine created with dialect = ODBC Driver 18 for SQL Server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine test sucessful\n",
      "starting process for docile\n",
      "https://api.mercadolibre.com/oauth/token?grant_type=refresh_token&client_id=1513566570673462&client_secret=RzJVVjutiiD02i3pmDciNtok9NYy6rw5&refresh_token=TG-657c7cb932d44e0001a4be81-1450787552\n",
      "https://api.mercadolibre.com/oauth/token?grant_type=refresh_token&client_id=1513566570673462&client_secret=RzJVVjutiiD02i3pmDciNtok9NYy6rw5&refresh_token=TG-657c7cb932d44e0001a4be81-1450787552\n",
      "time_from : 2023-12-08T00:00:00-00:00\n",
      "time_to : 2023-12-15T13:23:06-00:00\n",
      "https://api.mercadolibre.com/orders/search?seller=1450787552&order.date_created.from=2023-12-08T00:00:00-00:00&order.date_created.to=2023-12-15T13:23:06-00:00\n",
      "expected total orders: 96\n",
      "https://api.mercadolibre.com/orders/search?seller=1450787552&order.date_created.from=2023-12-08T00:00:00-00:00&order.date_created.to=2023-12-15T13:23:06-00:00&offset=0&limit=50&sort=date_desc\n",
      "next block:\n",
      "2000007158945450\n",
      "2000007158594872\n",
      "2000007158348456\n",
      "2000007157503856\n",
      "2000007156341624\n",
      "2000007152840764\n",
      "2000007151114958\n",
      "2000007151121340\n",
      "2000007151125190\n",
      "2000007150456556\n",
      "2000007149858672\n",
      "2000007149642268\n",
      "2000007149642266\n",
      "2000007148619498\n",
      "2000007147553450\n",
      "2000007147495434\n",
      "2000007147495410\n",
      "2000007145782582\n",
      "2000007145186520\n",
      "2000007144947548\n",
      "2000007144956828\n",
      "2000007144960708\n",
      "2000007144960710\n",
      "2000007144378734\n",
      "2000007144378736\n",
      "2000007144378716\n",
      "2000007142668576\n",
      "2000007141986208\n",
      "2000007140590650\n",
      "2000007140592464\n",
      "2000007139183240\n",
      "2000007137544110\n",
      "2000007136625286\n",
      "2000007134865750\n",
      "2000007133849812\n",
      "2000007133158126\n",
      "2000007132418074\n",
      "2000007130816840\n",
      "2000007129408674\n",
      "2000007129256550\n",
      "2000007129243966\n",
      "2000007127862268\n",
      "2000007127440532\n",
      "2000007127436552\n",
      "2000007127425662\n",
      "2000007126506450\n",
      "2000007126506496\n",
      "2000007126090748\n",
      "2000007123876812\n",
      "2000007120782684\n",
      "https://api.mercadolibre.com/orders/search?seller=1450787552&order.date_created.from=2023-12-08T00:00:00-00:00&order.date_created.to=2023-12-15T13:23:06-00:00&offset=50&limit=50&sort=date_desc\n",
      "next block:\n",
      "2000007120581566\n",
      "2000007120581572\n",
      "2000007117499098\n",
      "2000007116134048\n",
      "2000007115604332\n",
      "2000007115606078\n",
      "2000007114980516\n",
      "2000007114192576\n",
      "2000007114192578\n",
      "2000007114192580\n",
      "2000007114185578\n",
      "2000007113899722\n",
      "2000007113326556\n",
      "2000007113295830\n",
      "2000007113297422\n",
      "2000007113239006\n",
      "2000007113108632\n",
      "2000007112377058\n",
      "2000007112378798\n",
      "2000007111850006\n",
      "2000007108767196\n",
      "2000007108489410\n",
      "2000007107618500\n",
      "2000007105574956\n",
      "2000007105574946\n",
      "2000007105037840\n",
      "2000007103733818\n",
      "2000007103731764\n",
      "2000007102110120\n",
      "2000007102086304\n",
      "2000007100648690\n",
      "2000007098828850\n",
      "2000007098599352\n",
      "2000007098531290\n",
      "2000007096868790\n",
      "2000007095093858\n",
      "2000007094672462\n",
      "2000007092181520\n",
      "2000007092042740\n",
      "2000007090905706\n",
      "2000007088785644\n",
      "2000007088594122\n",
      "2000007088586946\n",
      "2000007088586940\n",
      "2000007088594188\n",
      "2000007088561976\n",
      "https://api.mercadolibre.com/users/1450787552\n",
      "https://api.mercadolibre.com/shipments/42912922866\n",
      "https://api.mercadolibre.com/shipments/42912645761\n",
      "https://api.mercadolibre.com/shipments/42912659276\n",
      "https://api.mercadolibre.com/shipments/42912159489\n",
      "https://api.mercadolibre.com/shipments/42911664027\n",
      "https://api.mercadolibre.com/shipments/42910164877\n",
      "https://api.mercadolibre.com/shipments/42909418623\n",
      "https://api.mercadolibre.com/shipments/42909546814\n",
      "https://api.mercadolibre.com/shipments/42909546814\n",
      "https://api.mercadolibre.com/shipments/42909130119\n",
      "https://api.mercadolibre.com/shipments/42908872579\n",
      "https://api.mercadolibre.com/shipments/42908900058\n",
      "https://api.mercadolibre.com/shipments/42908900058\n",
      "https://api.mercadolibre.com/shipments/42908453094\n",
      "https://api.mercadolibre.com/shipments/42907967254\n",
      "https://api.mercadolibre.com/shipments/42907815385\n",
      "https://api.mercadolibre.com/shipments/42907816315\n",
      "https://api.mercadolibre.com/shipments/42907094627\n",
      "https://api.mercadolibre.com/shipments/42906963186\n",
      "https://api.mercadolibre.com/shipments/42906743265\n",
      "https://api.mercadolibre.com/shipments/42906743265\n",
      "https://api.mercadolibre.com/shipments/42906743265\n",
      "https://api.mercadolibre.com/shipments/42906743265\n",
      "https://api.mercadolibre.com/shipments/42906492363\n",
      "https://api.mercadolibre.com/shipments/42906492363\n",
      "https://api.mercadolibre.com/shipments/42906615838\n",
      "https://api.mercadolibre.com/shipments/42905754029\n",
      "https://api.mercadolibre.com/shipments/42905451141\n",
      "https://api.mercadolibre.com/shipments/42904851979\n",
      "https://api.mercadolibre.com/shipments/42904975176\n",
      "https://api.mercadolibre.com/shipments/42904244835\n",
      "https://api.mercadolibre.com/shipments/42903521461\n",
      "https://api.mercadolibre.com/shipments/42903225030\n",
      "https://api.mercadolibre.com/shipments/42902513470\n",
      "https://api.mercadolibre.com/shipments/42901956167\n",
      "https://api.mercadolibre.com/shipments/42901652193\n",
      "https://api.mercadolibre.com/shipments/42901337215\n",
      "https://api.mercadolibre.com/shipments/42900640857\n",
      "https://api.mercadolibre.com/shipments/42900158664\n",
      "https://api.mercadolibre.com/shipments/42900092458\n",
      "https://api.mercadolibre.com/shipments/42900092458\n",
      "https://api.mercadolibre.com/shipments/42899368061\n",
      "https://api.mercadolibre.com/shipments/42899182603\n",
      "https://api.mercadolibre.com/shipments/42899182603\n",
      "https://api.mercadolibre.com/shipments/42899182603\n",
      "https://api.mercadolibre.com/shipments/42898762605\n",
      "https://api.mercadolibre.com/shipments/42898762629\n",
      "https://api.mercadolibre.com/shipments/42898572101\n",
      "https://api.mercadolibre.com/shipments/42897792564\n",
      "https://api.mercadolibre.com/shipments/42896473140\n",
      "https://api.mercadolibre.com/shipments/42896267443\n",
      "https://api.mercadolibre.com/shipments/42896267443\n",
      "https://api.mercadolibre.com/shipments/42894949861\n",
      "https://api.mercadolibre.com/shipments/42894469622\n",
      "https://api.mercadolibre.com/shipments/42894236046\n",
      "https://api.mercadolibre.com/shipments/42894236046\n",
      "https://api.mercadolibre.com/shipments/42893951850\n",
      "https://api.mercadolibre.com/shipments/42893524505\n",
      "https://api.mercadolibre.com/shipments/42893524505\n",
      "https://api.mercadolibre.com/shipments/42893524505\n",
      "https://api.mercadolibre.com/shipments/42893524499\n",
      "https://api.mercadolibre.com/shipments/42893411843\n",
      "https://api.mercadolibre.com/shipments/42893300276\n",
      "https://api.mercadolibre.com/shipments/42893168757\n",
      "https://api.mercadolibre.com/shipments/42893289580\n",
      "https://api.mercadolibre.com/shipments/42893264848\n",
      "https://api.mercadolibre.com/shipments/42893210784\n",
      "https://api.mercadolibre.com/shipments/42892909418\n",
      "https://api.mercadolibre.com/shipments/42892909418\n",
      "https://api.mercadolibre.com/shipments/42892573117\n",
      "https://api.mercadolibre.com/shipments/42891398986\n",
      "https://api.mercadolibre.com/shipments/42891161159\n",
      "https://api.mercadolibre.com/shipments/42890906484\n",
      "https://api.mercadolibre.com/shipments/42890041660\n",
      "https://api.mercadolibre.com/shipments/42890041660\n",
      "https://api.mercadolibre.com/shipments/42889698275\n",
      "https://api.mercadolibre.com/shipments/42889147903\n",
      "https://api.mercadolibre.com/shipments/42889147567\n",
      "https://api.mercadolibre.com/shipments/42888575594\n",
      "https://api.mercadolibre.com/shipments/42888444169\n",
      "https://api.mercadolibre.com/shipments/42887829227\n",
      "https://api.mercadolibre.com/shipments/42887042551\n",
      "https://api.mercadolibre.com/shipments/42886948757\n",
      "https://api.mercadolibre.com/shipments/42887040828\n",
      "https://api.mercadolibre.com/shipments/42886215625\n",
      "https://api.mercadolibre.com/shipments/42885577280\n",
      "https://api.mercadolibre.com/shipments/42885394942\n",
      "https://api.mercadolibre.com/shipments/42884324078\n",
      "https://api.mercadolibre.com/shipments/42884260018\n",
      "https://api.mercadolibre.com/shipments/42883731776\n",
      "https://api.mercadolibre.com/shipments/42882729427\n",
      "https://api.mercadolibre.com/shipments/42882762196\n",
      "https://api.mercadolibre.com/shipments/42882762196\n",
      "https://api.mercadolibre.com/shipments/42882762196\n",
      "https://api.mercadolibre.com/shipments/42882642433\n",
      "https://api.mercadolibre.com/shipments/42882754060\n",
      "96\n",
      "datapipeline_meli_functions starting mainInsertion time: 15/12/2023 13:23:30\n",
      "started errorHandle\n",
      "started errorHandle\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'failedDataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1905\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1905\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 736\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('42000', '[42000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Error converting data type varchar to float. (8114) (SQLExecDirectW)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 152\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    151\u001b[0m df_upsert(df_meli_payments_raw, utilities_load[file][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresultSuccessTable\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeli_payments_raw\u001b[39m\u001b[38;5;124m\"\u001b[39m], engine_azure, match_columns\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 152\u001b[0m \u001b[43mdf_upsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_meli_shipments_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutilities_load\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresultSuccessTable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeli_shipments_raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_azure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morder_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmainEndTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "Cell \u001b[1;32mIn[39], line 50\u001b[0m, in \u001b[0;36mdf_upsert\u001b[1;34m(data_frame, table_name, engine, schema, match_columns)\u001b[0m\n\u001b[0;32m     49\u001b[0m data_frame\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#temp_table\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m conn\u001b[38;5;241m.\u001b[39mexec_driver_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP TABLE IF EXISTS #temp_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1765\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1763\u001b[0m args_10style, kwargs_10style \u001b[38;5;241m=\u001b[39m _distill_params_20(parameters)\n\u001b[1;32m-> 1765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_10style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs_10style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1674\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[1;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[0;32m   1673\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1674\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future:\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1948\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1948\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2129\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2129\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:211\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1905\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1905\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\lucio.lee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:736\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 736\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (pyodbc.ProgrammingError) ('42000', '[42000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Error converting data type varchar to float. (8114) (SQLExecDirectW)')\n[SQL: MERGE [zmeli_testshipments_raw] WITH (HOLDLOCK) AS main\nUSING (SELECT [receiver_id], [base_cost], [type], [return_details], [sender_id], [mode], [order_cost], [service_id], [tracking_number], [id], [tracking_method], [last_updated], [comments], [substatus], [date_created], [date_first_printed], [created_by], [application_id], [return_tracking_number], [site_id], [carrier_info], [market_place], [customer_id], [order_id], [quotation], [status], [logistic_type], [snapshot_packing_snapshot_id], [snapshot_packing_pack_hash], [status_history_date_shipped], [status_history_date_returned], [status_history_date_delivered], [status_history_date_first_visit], [status_history_date_not_delivered], [status_history_date_cancelled], [status_history_date_handling], [status_history_date_ready_to_ship], [priority_class_id], [cost_components_loyal_discount], [cost_components_special_discount], [cost_components_compensation], [cost_components_gap_discount], [cost_components_ratio], [shipping_option_processing_time], [shipping_option_cost], [shipping_option_estimated_schedule_limit_date], [shipping_option_shipping_method_id], [shipping_option_estimated_delivery_final_date], [shipping_option_estimated_delivery_final_offset], [shipping_option_buffering_date], [shipping_option_pickup_promise_from], [shipping_option_pickup_promise_to], [shipping_option_list_cost], [shipping_option_estimated_delivery_limit_date], [shipping_option_estimated_delivery_limit_offset], [shipping_option_priority_class_id], [shipping_option_delivery_promise], [shipping_option_delivery_type], [shipping_option_estimated_handling_limit_date], [shipping_option_estimated_delivery_time_date], [shipping_option_estimated_delivery_time_pay_before], [shipping_option_estimated_delivery_time_schedule], [shipping_option_estimated_delivery_time_unit], [shipping_option_estimated_delivery_time_offset_date], [shipping_option_estimated_delivery_time_offset_shipping], [shipping_option_estimated_delivery_time_shipping], [shipping_option_estimated_delivery_time_time_frame_from], [shipping_option_estimated_delivery_time_time_frame_to], [shipping_option_estimated_delivery_time_handling], [shipping_option_estimated_delivery_time_type], [shipping_option_name], [shipping_option_id], [shipping_option_estimated_delivery_extended_date], [shipping_option_estimated_delivery_extended_offset], [shipping_option_currency_id], [sender_address_country_id], [sender_address_country_name], [sender_address_address_line], [sender_address_scoring], [sender_address_agency], [sender_address_city_id], [sender_address_city_name], [sender_address_geolocation_type], [sender_address_latitude], [sender_address_municipality_id], [sender_address_municipality_name], [sender_address_location_id], [sender_address_street_name], [sender_address_zip_code], [sender_address_geolocation_source], [sender_address_intersection], [sender_address_street_number], [sender_address_comment], [sender_address_id], [sender_address_state_id], [sender_address_state_name], [sender_address_neighborhood_id], [sender_address_neighborhood_name], [sender_address_geolocation_last_updated], [sender_address_longitude], [sibling_reason], [sibling_sibling_id], [sibling_description], [sibling_source], [sibling_date_created], [sibling_last_updated], [receiver_address_country_id], [receiver_address_country_name], [receiver_address_address_line], [receiver_address_scoring], [receiver_address_agency], [receiver_address_city_id], [receiver_address_city_name], [receiver_address_geolocation_type], [receiver_address_latitude], [receiver_address_municipality_id], [receiver_address_municipality_name], [receiver_address_location_id], [receiver_address_street_name], [receiver_address_zip_code], [receiver_address_geolocation_source], [receiver_address_delivery_preference], [receiver_address_intersection], [receiver_address_street_number], [receiver_address_receiver_name], [receiver_address_comment], [receiver_address_id], [receiver_address_state_id], [receiver_address_state_name], [receiver_address_neighborhood_id], [receiver_address_neighborhood_name], [receiver_address_geolocation_last_updated], [receiver_address_receiver_phone], [receiver_address_longitude] FROM #temp_table) AS temp\nON (main.[id] = temp.[id] AND main.[order_id] = temp.[order_id])\nWHEN MATCHED THEN\n  UPDATE SET [receiver_id] = temp.[receiver_id], [base_cost] = temp.[base_cost], [type] = temp.[type], [return_details] = temp.[return_details], [sender_id] = temp.[sender_id], [mode] = temp.[mode], [order_cost] = temp.[order_cost], [service_id] = temp.[service_id], [tracking_number] = temp.[tracking_number], [tracking_method] = temp.[tracking_method], [last_updated] = temp.[last_updated], [comments] = temp.[comments], [substatus] = temp.[substatus], [date_created] = temp.[date_created], [date_first_printed] = temp.[date_first_printed], [created_by] = temp.[created_by], [application_id] = temp.[application_id], [return_tracking_number] = temp.[return_tracking_number], [site_id] = temp.[site_id], [carrier_info] = temp.[carrier_info], [market_place] = temp.[market_place], [customer_id] = temp.[customer_id], [quotation] = temp.[quotation], [status] = temp.[status], [logistic_type] = temp.[logistic_type], [snapshot_packing_snapshot_id] = temp.[snapshot_packing_snapshot_id], [snapshot_packing_pack_hash] = temp.[snapshot_packing_pack_hash], [status_history_date_shipped] = temp.[status_history_date_shipped], [status_history_date_returned] = temp.[status_history_date_returned], [status_history_date_delivered] = temp.[status_history_date_delivered], [status_history_date_first_visit] = temp.[status_history_date_first_visit], [status_history_date_not_delivered] = temp.[status_history_date_not_delivered], [status_history_date_cancelled] = temp.[status_history_date_cancelled], [status_history_date_handling] = temp.[status_history_date_handling], [status_history_date_ready_to_ship] = temp.[status_history_date_ready_to_ship], [priority_class_id] = temp.[priority_class_id], [cost_components_loyal_discount] = temp.[cost_components_loyal_discount], [cost_components_special_discount] = temp.[cost_components_special_discount], [cost_components_compensation] = temp.[cost_components_compensation], [cost_components_gap_discount] = temp.[cost_components_gap_discount], [cost_components_ratio] = temp.[cost_components_ratio], [shipping_option_processing_time] = temp.[shipping_option_processing_time], [shipping_option_cost] = temp.[shipping_option_cost], [shipping_option_estimated_schedule_limit_date] = temp.[shipping_option_estimated_schedule_limit_date], [shipping_option_shipping_method_id] = temp.[shipping_option_shipping_method_id], [shipping_option_estimated_delivery_final_date] = temp.[shipping_option_estimated_delivery_final_date], [shipping_option_estimated_delivery_final_offset] = temp.[shipping_option_estimated_delivery_final_offset], [shipping_option_buffering_date] = temp.[shipping_option_buffering_date], [shipping_option_pickup_promise_from] = temp.[shipping_option_pickup_promise_from], [shipping_option_pickup_promise_to] = temp.[shipping_option_pickup_promise_to], [shipping_option_list_cost] = temp.[shipping_option_list_cost], [shipping_option_estimated_delivery_limit_date] = temp.[shipping_option_estimated_delivery_limit_date], [shipping_option_estimated_delivery_limit_offset] = temp.[shipping_option_estimated_delivery_limit_offset], [shipping_option_priority_class_id] = temp.[shipping_option_priority_class_id], [shipping_option_delivery_promise] = temp.[shipping_option_delivery_promise], [shipping_option_delivery_type] = temp.[shipping_option_delivery_type], [shipping_option_estimated_handling_limit_date] = temp.[shipping_option_estimated_handling_limit_date], [shipping_option_estimated_delivery_time_date] = temp.[shipping_option_estimated_delivery_time_date], [shipping_option_estimated_delivery_time_pay_before] = temp.[shipping_option_estimated_delivery_time_pay_before], [shipping_option_estimated_delivery_time_schedule] = temp.[shipping_option_estimated_delivery_time_schedule], [shipping_option_estimated_delivery_time_unit] = temp.[shipping_option_estimated_delivery_time_unit], [shipping_option_estimated_delivery_time_offset_date] = temp.[shipping_option_estimated_delivery_time_offset_date], [shipping_option_estimated_delivery_time_offset_shipping] = temp.[shipping_option_estimated_delivery_time_offset_shipping], [shipping_option_estimated_delivery_time_shipping] = temp.[shipping_option_estimated_delivery_time_shipping], [shipping_option_estimated_delivery_time_time_frame_from] = temp.[shipping_option_estimated_delivery_time_time_frame_from], [shipping_option_estimated_delivery_time_time_frame_to] = temp.[shipping_option_estimated_delivery_time_time_frame_to], [shipping_option_estimated_delivery_time_handling] = temp.[shipping_option_estimated_delivery_time_handling], [shipping_option_estimated_delivery_time_type] = temp.[shipping_option_estimated_delivery_time_type], [shipping_option_name] = temp.[shipping_option_name], [shipping_option_id] = temp.[shipping_option_id], [shipping_option_estimated_delivery_extended_date] = temp.[shipping_option_estimated_delivery_extended_date], [shipping_option_estimated_delivery_extended_offset] = temp.[shipping_option_estimated_delivery_extended_offset], [shipping_option_currency_id] = temp.[shipping_option_currency_id], [sender_address_country_id] = temp.[sender_address_country_id], [sender_address_country_name] = temp.[sender_address_country_name], [sender_address_address_line] = temp.[sender_address_address_line], [sender_address_scoring] = temp.[sender_address_scoring], [sender_address_agency] = temp.[sender_address_agency], [sender_address_city_id] = temp.[sender_address_city_id], [sender_address_city_name] = temp.[sender_address_city_name], [sender_address_geolocation_type] = temp.[sender_address_geolocation_type], [sender_address_latitude] = temp.[sender_address_latitude], [sender_address_municipality_id] = temp.[sender_address_municipality_id], [sender_address_municipality_name] = temp.[sender_address_municipality_name], [sender_address_location_id] = temp.[sender_address_location_id], [sender_address_street_name] = temp.[sender_address_street_name], [sender_address_zip_code] = temp.[sender_address_zip_code], [sender_address_geolocation_source] = temp.[sender_address_geolocation_source], [sender_address_intersection] = temp.[sender_address_intersection], [sender_address_street_number] = temp.[sender_address_street_number], [sender_address_comment] = temp.[sender_address_comment], [sender_address_id] = temp.[sender_address_id], [sender_address_state_id] = temp.[sender_address_state_id], [sender_address_state_name] = temp.[sender_address_state_name], [sender_address_neighborhood_id] = temp.[sender_address_neighborhood_id], [sender_address_neighborhood_name] = temp.[sender_address_neighborhood_name], [sender_address_geolocation_last_updated] = temp.[sender_address_geolocation_last_updated], [sender_address_longitude] = temp.[sender_address_longitude], [sibling_reason] = temp.[sibling_reason], [sibling_sibling_id] = temp.[sibling_sibling_id], [sibling_description] = temp.[sibling_description], [sibling_source] = temp.[sibling_source], [sibling_date_created] = temp.[sibling_date_created], [sibling_last_updated] = temp.[sibling_last_updated], [receiver_address_country_id] = temp.[receiver_address_country_id], [receiver_address_country_name] = temp.[receiver_address_country_name], [receiver_address_address_line] = temp.[receiver_address_address_line], [receiver_address_scoring] = temp.[receiver_address_scoring], [receiver_address_agency] = temp.[receiver_address_agency], [receiver_address_city_id] = temp.[receiver_address_city_id], [receiver_address_city_name] = temp.[receiver_address_city_name], [receiver_address_geolocation_type] = temp.[receiver_address_geolocation_type], [receiver_address_latitude] = temp.[receiver_address_latitude], [receiver_address_municipality_id] = temp.[receiver_address_municipality_id], [receiver_address_municipality_name] = temp.[receiver_address_municipality_name], [receiver_address_location_id] = temp.[receiver_address_location_id], [receiver_address_street_name] = temp.[receiver_address_street_name], [receiver_address_zip_code] = temp.[receiver_address_zip_code], [receiver_address_geolocation_source] = temp.[receiver_address_geolocation_source], [receiver_address_delivery_preference] = temp.[receiver_address_delivery_preference], [receiver_address_intersection] = temp.[receiver_address_intersection], [receiver_address_street_number] = temp.[receiver_address_street_number], [receiver_address_receiver_name] = temp.[receiver_address_receiver_name], [receiver_address_comment] = temp.[receiver_address_comment], [receiver_address_id] = temp.[receiver_address_id], [receiver_address_state_id] = temp.[receiver_address_state_id], [receiver_address_state_name] = temp.[receiver_address_state_name], [receiver_address_neighborhood_id] = temp.[receiver_address_neighborhood_id], [receiver_address_neighborhood_name] = temp.[receiver_address_neighborhood_name], [receiver_address_geolocation_last_updated] = temp.[receiver_address_geolocation_last_updated], [receiver_address_receiver_phone] = temp.[receiver_address_receiver_phone], [receiver_address_longitude] = temp.[receiver_address_longitude]\nWHEN NOT MATCHED THEN\n  INSERT ([receiver_id], [base_cost], [type], [return_details], [sender_id], [mode], [order_cost], [service_id], [tracking_number], [id], [tracking_method], [last_updated], [comments], [substatus], [date_created], [date_first_printed], [created_by], [application_id], [return_tracking_number], [site_id], [carrier_info], [market_place], [customer_id], [order_id], [quotation], [status], [logistic_type], [snapshot_packing_snapshot_id], [snapshot_packing_pack_hash], [status_history_date_shipped], [status_history_date_returned], [status_history_date_delivered], [status_history_date_first_visit], [status_history_date_not_delivered], [status_history_date_cancelled], [status_history_date_handling], [status_history_date_ready_to_ship], [priority_class_id], [cost_components_loyal_discount], [cost_components_special_discount], [cost_components_compensation], [cost_components_gap_discount], [cost_components_ratio], [shipping_option_processing_time], [shipping_option_cost], [shipping_option_estimated_schedule_limit_date], [shipping_option_shipping_method_id], [shipping_option_estimated_delivery_final_date], [shipping_option_estimated_delivery_final_offset], [shipping_option_buffering_date], [shipping_option_pickup_promise_from], [shipping_option_pickup_promise_to], [shipping_option_list_cost], [shipping_option_estimated_delivery_limit_date], [shipping_option_estimated_delivery_limit_offset], [shipping_option_priority_class_id], [shipping_option_delivery_promise], [shipping_option_delivery_type], [shipping_option_estimated_handling_limit_date], [shipping_option_estimated_delivery_time_date], [shipping_option_estimated_delivery_time_pay_before], [shipping_option_estimated_delivery_time_schedule], [shipping_option_estimated_delivery_time_unit], [shipping_option_estimated_delivery_time_offset_date], [shipping_option_estimated_delivery_time_offset_shipping], [shipping_option_estimated_delivery_time_shipping], [shipping_option_estimated_delivery_time_time_frame_from], [shipping_option_estimated_delivery_time_time_frame_to], [shipping_option_estimated_delivery_time_handling], [shipping_option_estimated_delivery_time_type], [shipping_option_name], [shipping_option_id], [shipping_option_estimated_delivery_extended_date], [shipping_option_estimated_delivery_extended_offset], [shipping_option_currency_id], [sender_address_country_id], [sender_address_country_name], [sender_address_address_line], [sender_address_scoring], [sender_address_agency], [sender_address_city_id], [sender_address_city_name], [sender_address_geolocation_type], [sender_address_latitude], [sender_address_municipality_id], [sender_address_municipality_name], [sender_address_location_id], [sender_address_street_name], [sender_address_zip_code], [sender_address_geolocation_source], [sender_address_intersection], [sender_address_street_number], [sender_address_comment], [sender_address_id], [sender_address_state_id], [sender_address_state_name], [sender_address_neighborhood_id], [sender_address_neighborhood_name], [sender_address_geolocation_last_updated], [sender_address_longitude], [sibling_reason], [sibling_sibling_id], [sibling_description], [sibling_source], [sibling_date_created], [sibling_last_updated], [receiver_address_country_id], [receiver_address_country_name], [receiver_address_address_line], [receiver_address_scoring], [receiver_address_agency], [receiver_address_city_id], [receiver_address_city_name], [receiver_address_geolocation_type], [receiver_address_latitude], [receiver_address_municipality_id], [receiver_address_municipality_name], [receiver_address_location_id], [receiver_address_street_name], [receiver_address_zip_code], [receiver_address_geolocation_source], [receiver_address_delivery_preference], [receiver_address_intersection], [receiver_address_street_number], [receiver_address_receiver_name], [receiver_address_comment], [receiver_address_id], [receiver_address_state_id], [receiver_address_state_name], [receiver_address_neighborhood_id], [receiver_address_neighborhood_name], [receiver_address_geolocation_last_updated], [receiver_address_receiver_phone], [receiver_address_longitude]) VALUES (temp.[receiver_id], temp.[base_cost], temp.[type], temp.[return_details], temp.[sender_id], temp.[mode], temp.[order_cost], temp.[service_id], temp.[tracking_number], temp.[id], temp.[tracking_method], temp.[last_updated], temp.[comments], temp.[substatus], temp.[date_created], temp.[date_first_printed], temp.[created_by], temp.[application_id], temp.[return_tracking_number], temp.[site_id], temp.[carrier_info], temp.[market_place], temp.[customer_id], temp.[order_id], temp.[quotation], temp.[status], temp.[logistic_type], temp.[snapshot_packing_snapshot_id], temp.[snapshot_packing_pack_hash], temp.[status_history_date_shipped], temp.[status_history_date_returned], temp.[status_history_date_delivered], temp.[status_history_date_first_visit], temp.[status_history_date_not_delivered], temp.[status_history_date_cancelled], temp.[status_history_date_handling], temp.[status_history_date_ready_to_ship], temp.[priority_class_id], temp.[cost_components_loyal_discount], temp.[cost_components_special_discount], temp.[cost_components_compensation], temp.[cost_components_gap_discount], temp.[cost_components_ratio], temp.[shipping_option_processing_time], temp.[shipping_option_cost], temp.[shipping_option_estimated_schedule_limit_date], temp.[shipping_option_shipping_method_id], temp.[shipping_option_estimated_delivery_final_date], temp.[shipping_option_estimated_delivery_final_offset], temp.[shipping_option_buffering_date], temp.[shipping_option_pickup_promise_from], temp.[shipping_option_pickup_promise_to], temp.[shipping_option_list_cost], temp.[shipping_option_estimated_delivery_limit_date], temp.[shipping_option_estimated_delivery_limit_offset], temp.[shipping_option_priority_class_id], temp.[shipping_option_delivery_promise], temp.[shipping_option_delivery_type], temp.[shipping_option_estimated_handling_limit_date], temp.[shipping_option_estimated_delivery_time_date], temp.[shipping_option_estimated_delivery_time_pay_before], temp.[shipping_option_estimated_delivery_time_schedule], temp.[shipping_option_estimated_delivery_time_unit], temp.[shipping_option_estimated_delivery_time_offset_date], temp.[shipping_option_estimated_delivery_time_offset_shipping], temp.[shipping_option_estimated_delivery_time_shipping], temp.[shipping_option_estimated_delivery_time_time_frame_from], temp.[shipping_option_estimated_delivery_time_time_frame_to], temp.[shipping_option_estimated_delivery_time_handling], temp.[shipping_option_estimated_delivery_time_type], temp.[shipping_option_name], temp.[shipping_option_id], temp.[shipping_option_estimated_delivery_extended_date], temp.[shipping_option_estimated_delivery_extended_offset], temp.[shipping_option_currency_id], temp.[sender_address_country_id], temp.[sender_address_country_name], temp.[sender_address_address_line], temp.[sender_address_scoring], temp.[sender_address_agency], temp.[sender_address_city_id], temp.[sender_address_city_name], temp.[sender_address_geolocation_type], temp.[sender_address_latitude], temp.[sender_address_municipality_id], temp.[sender_address_municipality_name], temp.[sender_address_location_id], temp.[sender_address_street_name], temp.[sender_address_zip_code], temp.[sender_address_geolocation_source], temp.[sender_address_intersection], temp.[sender_address_street_number], temp.[sender_address_comment], temp.[sender_address_id], temp.[sender_address_state_id], temp.[sender_address_state_name], temp.[sender_address_neighborhood_id], temp.[sender_address_neighborhood_name], temp.[sender_address_geolocation_last_updated], temp.[sender_address_longitude], temp.[sibling_reason], temp.[sibling_sibling_id], temp.[sibling_description], temp.[sibling_source], temp.[sibling_date_created], temp.[sibling_last_updated], temp.[receiver_address_country_id], temp.[receiver_address_country_name], temp.[receiver_address_address_line], temp.[receiver_address_scoring], temp.[receiver_address_agency], temp.[receiver_address_city_id], temp.[receiver_address_city_name], temp.[receiver_address_geolocation_type], temp.[receiver_address_latitude], temp.[receiver_address_municipality_id], temp.[receiver_address_municipality_name], temp.[receiver_address_location_id], temp.[receiver_address_street_name], temp.[receiver_address_zip_code], temp.[receiver_address_geolocation_source], temp.[receiver_address_delivery_preference], temp.[receiver_address_intersection], temp.[receiver_address_street_number], temp.[receiver_address_receiver_name], temp.[receiver_address_comment], temp.[receiver_address_id], temp.[receiver_address_state_id], temp.[receiver_address_state_name], temp.[receiver_address_neighborhood_id], temp.[receiver_address_neighborhood_name], temp.[receiver_address_geolocation_last_updated], temp.[receiver_address_receiver_phone], temp.[receiver_address_longitude]);]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 165\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m         \u001b[43merrorHandle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minsertAzureDB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_azure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m#if there is no data after TransID then call successHandle\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 12\u001b[0m, in \u001b[0;36merrorHandle\u001b[1;34m(errSeverity, errReason, additionalInfo, file, engine_azure)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted errorHandle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m errProcedure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merrorSuggestedProcedure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43merrReason\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m additionalInfo \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'insertAzureDB'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m start time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: done with the output: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, runtime \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(file, \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m], (\u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtotal_seconds()))\n",
      "Cell \u001b[1;32mIn[41], line 174\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    172\u001b[0m         successHandle(file\u001b[38;5;241m=\u001b[39m file, additionalInfo\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno new trans_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, runRowNumber\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, engine_azure \u001b[38;5;241m=\u001b[39m engine_azure)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     \u001b[43merrorHandle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfailedDataFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_azure\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 12\u001b[0m, in \u001b[0;36merrorHandle\u001b[1;34m(errSeverity, errReason, additionalInfo, file, engine_azure)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mHandles error for logging in AzureDB:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03merrLocation should be: where is running, application that is running + file name, other info\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mthe connection is the connection for the AzureDB\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted errorHandle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m errProcedure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merrorSuggestedProcedure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43merrReason\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m additionalInfo \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     errDescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutil\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m][errReason]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'failedDataFrame'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file = \"datapipeline_meli_functions\"\n",
    "    print (f'{file} start time: {datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}')\n",
    "    globals()['startTime'] = datetime.now()\n",
    "    \n",
    "    main(file)\n",
    "    globals()['endTime'] = datetime.now()\n",
    "    print('%s: done with the output: %s, runtime %s' %(file, globals()['output'], (globals()['endTime'] - globals()['startTime']).total_seconds()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
